{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance Sampling in Talyn\n",
    "\n",
    "This notebook introduces likelihood-free inference using importance sampling in Talyn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Estimate $E[f(x)]$ Under Target Using Proposal Samples\n",
    "\n",
    "Suppose our target is $N(0,1)$ and our proposal is $N(2,1)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "N = 1000\n",
    "proposal = np.random.normal(2, 1, N)\n",
    "target_pdf = norm.pdf(proposal, 0, 1)\n",
    "proposal_pdf = norm.pdf(proposal, 2, 1)\n",
    "weights = target_pdf / proposal_pdf\n",
    "f_x = proposal**2\n",
    "estimate = np.sum(f_x * weights) / np.sum(weights)\n",
    "print('Importance sampling estimate of E[x^2] under N(0,1):', estimate)\n",
    "print('True value:', 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Weights and Bias\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(weights, bins=30, alpha=0.7, color='orange')\n",
    "plt.title('Importance Weights', fontsize=14)\n",
    "plt.xlabel('Weight', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement Multiple Proposals\n",
    "\n",
    "We can mix proposals to reduce variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "proposal1 = np.random.normal(2, 1, N//2)\n",
    "proposal2 = np.random.normal(-2, 1, N//2)\n",
    "all_samples = np.concatenate([proposal1, proposal2])\n",
    "all_proposal_pdf = 0.5*norm.pdf(all_samples, 2, 1) + 0.5*norm.pdf(all_samples, -2, 1)\n",
    "all_target_pdf = norm.pdf(all_samples, 0, 1)\n",
    "all_weights = all_target_pdf / all_proposal_pdf\n",
    "estimate_multi = np.sum(all_samples**2 * all_weights) / np.sum(all_weights)\n",
    "print('Estimate with multiple proposals:', estimate_multi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze High-Variance Cases and Collapse\n",
    "\n",
    "If the proposal is very different from the target, weights become highly variable and the estimate collapses.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "bad_proposal = np.random.normal(10, 1, N)\n",
    "bad_weights = norm.pdf(bad_proposal, 0, 1) / norm.pdf(bad_proposal, 10, 1)\n",
    "print('Effective sample size:', 1.0/np.sum(bad_weights**2))\n",
    "print('Estimate:', np.sum(bad_proposal**2 * bad_weights) / np.sum(bad_weights))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook introduced importance sampling in Talyn. Next, we'll explore ABC inference.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
