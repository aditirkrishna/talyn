{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models (HMMs) in Talyn\n",
    "\n",
    "This notebook demonstrates how to define, simulate, and infer on basic Hidden Markov Models (HMMs) in Talyn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Transition and Emission Matrices\n",
    "\n",
    "We define a simple 2-state HMM.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "states = [0, 1]\n",
    "transition = np.array([[0.8, 0.2], [0.3, 0.7]])  # P(next|current)\n",
    "emission = np.array([[0.9, 0.1], [0.2, 0.8]])    # P(obs|state)\n",
    "print('Transition matrix:\n', transition)\n",
    "print('Emission matrix:\n', emission)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Forward Sampling\n",
    "\n",
    "Let's simulate a sequence of hidden and observed states.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sample_hmm(T=10):\n",
    "    hidden = [np.random.choice(states)]\n",
    "    observed = []\n",
    "    for t in range(T):\n",
    "        s = hidden[-1]\n",
    "        o = np.random.choice([0,1], p=emission[s])\n",
    "        observed.append(o)\n",
    "        if t < T-1:\n",
    "            next_s = np.random.choice(states, p=transition[s])\n",
    "            hidden.append(next_s)\n",
    "    return hidden, observed\n",
    "hidden, observed = sample_hmm(20)\n",
    "print('Hidden:', hidden)\n",
    "print('Observed:', observed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Sequence of Hidden and Observed States\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.plot(hidden, 'o-', label='Hidden State')\n",
    "plt.plot(observed, 'x--', label='Observed')\n",
    "plt.legend(fontsize=12)\n",
    "plt.title('HMM: Hidden and Observed States', fontsize=14)\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.yticks([0,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decode MAP Path (Viterbi Algorithm)\n",
    "\n",
    "Let's implement the Viterbi algorithm to decode the most likely sequence of hidden states.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def viterbi(obs, transition, emission):\n",
    "    T = len(obs)\n",
    "    N = transition.shape[0]\n",
    "    dp = np.zeros((T, N))\n",
    "    ptr = np.zeros((T, N), dtype=int)\n",
    "    dp[0] = 0.5 * emission[:, obs[0]]\n",
    "    for t in range(1, T):\n",
    "        for j in range(N):\n",
    "            probs = dp[t-1] * transition[:,j] * emission[j, obs[t]]\n",
    "            ptr[t, j] = np.argmax(probs)\n",
    "            dp[t, j] = np.max(probs)\n",
    "    path = [np.argmax(dp[-1])]\n",
    "    for t in range(T-1, 0, -1):\n",
    "        path.append(ptr[t, path[-1]])\n",
    "    return path[::-1]\n",
    "viterbi_path = viterbi(observed, transition, emission)\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.plot(viterbi_path, 's-', label='Viterbi Path')\n",
    "plt.plot(hidden, 'o--', label='True Hidden')\n",
    "plt.legend(fontsize=12)\n",
    "plt.title('Viterbi Decoding vs True Hidden States', fontsize=14)\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.yticks([0,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference Over Latent State Probabilities\n",
    "\n",
    "We can compute the probability of each hidden state at each time step (forward-backward algorithm).\n    (For brevity, we illustrate the concept.)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Placeholder: In practice, use Talyn's inference modules for forward-backward\n",
    "print('Forward-backward inference not shown in detail here.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook introduced HMMs in Talyn. Next, we'll explore Kalman filter inference.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
